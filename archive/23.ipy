# %%
# SDG vs Real Data Comparison: Step-by-Step Implementation
# File: sdg_real_synthetic_comparison.py

"""
This script tests whether a Synthetic Data Generator (SDG) can accurately replicate real-world temperature time series data.
We follow these steps:
1. Imports & Configuration
2. Load & Preprocess Data
3. Hyperparameter Estimation from Real Data
   - AR order (p) via AIC/BIC
   - Seasonal frequencies via periodogram peak detection
   - Trend via linear regression
4. Component Extraction (Trend, Seasonality, AR residuals)
5. Synthetic Data Generation using SDG
6. Statistical & Structural Testing
   - Marginal stats (mean, variance)
   - Dependence (ACF, PSD)
   - Distributional (KS test, MMD)
   - Temporal alignment (DTW)
   - Structural parameter recovery (compare estimated vs true params)
   - Classification-based distinguishability
7. Metrics Summary & Visualization

Each block includes detailed explanations of metrics and methods.
"""

# %% 1. Imports & Configuration
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.ar_model import AutoReg
from statsmodels.tsa.stattools import acf
from scipy.signal import periodogram, find_peaks
from scipy.stats import ks_2samp
from sklearn.metrics import pairwise_distances, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from scipy.spatial.distance import euclidean

# Reproducibility
np.random.seed(42)

# %% 2. Load & Preprocess Data
# -------------------------
csv_path = './data/weather/temp.csv'
df = pd.read_csv(csv_path, parse_dates=['date'], index_col='date')
# Extract series
y = df['T (degC)'].values
nt = len(y)
t_idx = np.arange(nt)

print(f"Loaded {nt} observations of real temperature data.")
print(df.head())

# %% 3. Hyperparameter Estimation from Real Data
# ---------------------------------------------
# 3.1 Trend estimation via linear regression
beta, c = np.polyfit(t_idx, y, 1)
trend = beta * t_idx + c
print(f"Estimated linear trend: slope={beta:.4f}, intercept={c:.4f}")

# 3.2 Seasonal frequency detection using periodogram on detrended data
resid_tr = y - trend
freqs, Pxx = periodogram(resid_tr)
peaks_idx, _ = find_peaks(Pxx)
peak_freqs = freqs[peaks_idx]
peak_powers = Pxx[peaks_idx]
# Identify top two peaks by power
idx_top = np.argsort(peak_powers)[-2:]
top_freqs = peak_freqs[idx_top]
# Convert frequencies to periods (in samples)
periods = np.round(1 / top_freqs).astype(int)
T_season1, T_season2 = periods
print(f"Detected seasonal periods (in samples): {T_season1}, {T_season2}")

# 3.3 AR order estimation via AIC/BIC on detrended residuals
max_lag = 30
aic_vals = []
bic_vals = []
for lag in range(1, max_lag + 1):
    model = AutoReg(resid_tr, lags=lag, old_names=False).fit()
    aic_vals.append(model.aic)
    bic_vals.append(model.bic)
best_p_aic = np.argmin(aic_vals) + 1
best_p_bic = np.argmin(bic_vals) + 1
p = best_p_aic
print(f"Selected AR order by AIC: {best_p_aic}, by BIC: {best_p_bic}")

# %% 4. Component Extraction & Visualization
# ------------------------------------------
# 4.1 Reconstruct trend (already in 'trend')
# 4.2 Seasonal components via sinusoidal regression
X_season = np.column_stack([
    np.sin(2 * np.pi * t_idx / T_season1),
    np.cos(2 * np.pi * t_idx / T_season1),
    np.sin(2 * np.pi * t_idx / T_season2),
    np.cos(2 * np.pi * t_idx / T_season2)
])
# Fit amplitudes
alpha, *_ = np.linalg.lstsq(X_season, y - trend, rcond=None)
# Daily/primary seasonal
A1 = np.hypot(alpha[0], alpha[1]); phi1 = np.arctan2(alpha[1], alpha[0])
# Secondary seasonal
A2 = np.hypot(alpha[2], alpha[3]); phi2 = np.arctan2(alpha[3], alpha[2])
season1 = A1 * np.sin(2 * np.pi * t_idx / T_season1 + phi1)
season2 = A2 * np.sin(2 * np.pi * t_idx / T_season2 + phi2)
seasonal = season1 + season2

# 4.3 Residuals after removing trend + seasonality
residuals = y - trend - seasonal

# Visualization
fig, ax = plt.subplots(3, 1, figsize=(12, 8), sharex=True)
ax[0].plot(df.index, y, label='Original')
ax[0].plot(df.index, trend, label='Trend')
ax[0].legend(); ax[0].set_title('Trend')
ax[1].plot(df.index, residuals + seasonal, label='Seasonal')
ax[1].set_title('Seasonal Components')
ax[2].plot(df.index, residuals, label='Residuals')
ax[2].set_title('AR Residuals (to model)')
plt.tight_layout(); plt.show()

# %% 5. Synthetic Data Generation using SDG
# -----------------------------------------
# 5.1 Fit AR(p) to residuals
ar_model = AutoReg(residuals, lags=p, old_names=False).fit()
phi_params = ar_model.params[1:]
sigma = np.sqrt(ar_model.sigma2)
print(f"AR coefficients: {phi_params} Innovation std: {sigma:.4f}")

# 5.2 Generate synthetic residuals
epsilon = np.random.normal(0, sigma, size=nt)
syn_resid = np.zeros(nt)
syn_resid[:p] = residuals[:p]
for i in range(p, nt):
    syn_resid[i] = phi_params @ syn_resid[i-p:i][::-1] + epsilon[i]

# 5.3 Compose synthetic series
synthetic = trend + seasonal + syn_resid

series_real = pd.Series(y, index=df.index, name='Real')
series_syn = pd.Series(synthetic, index=df.index, name='Synthetic')

plt.figure(figsize=(12, 4))
series_real.plot(label='Real')
series_syn.plot(label='Synthetic', alpha=0.7)
plt.legend(); plt.title('Real vs Synthetic'); plt.show()

# %% 6. Statistical & Structural Testing
# -------------------------------------
metrics = {}

# 6.1 Marginal statistics: mean, variance
df_stat = pd.DataFrame({
    'Real': [series_real.mean(), series_real.var()],
    'Synthetic': [series_syn.mean(), series_syn.var()]
}, index=['Mean', 'Variance'])
print(df_stat)
metrics['Mean Diff'] = series_real.mean() - series_syn.mean()
metrics['Var Diff'] = series_real.var() - series_syn.var()

# 6.2 ACF distance
def acf_l2(x, y, nlags=30):
    return np.sum((acf(x, nlags=nlags, fft=True) - acf(y, nlags=nlags, fft=True))**2)
metrics['ACF L2'] = acf_l2(series_real, series_syn)

# 6.3 PSD distance
def psd_l2(x, y):
    fx, Px = periodogram(x)
    fy, Py = periodogram(y)
    return np.sum((Px - Py)**2)
metrics['PSD L2'] = psd_l2(series_real, series_syn)

# 6.4 KS test
ksd, ksp = ks_2samp(series_real, series_syn)
metrics['KS Stat'] = ksd; metrics['KS p'] = ksp

# 6.5 MMD (subsample)
def mmd_sub(x, y, m=500):
    ix = np.random.choice(len(x), m, replace=False)
    iy = np.random.choice(len(y), m, replace=False)
    Xs, Ys = x[ix].reshape(-1,1), y[iy].reshape(-1,1)
    Z = np.vstack([Xs, Ys])
    sig = np.median(pairwise_distances(Z))
    Kxx = np.exp(-pairwise_distances(Xs, Xs, squared=True)/(2*sig**2))
    Kyy = np.exp(-pairwise_distances(Ys, Ys, squared=True)/(2*sig**2))
    Kxy = np.exp(-pairwise_distances(Xs, Ys, squared=True)/(2*sig**2))
    m, n_ = len(Xs), len(Ys)
    return ((Kxx.sum()-np.trace(Kxx))/(m*(m-1)) +
            (Kyy.sum()-np.trace(Kyy))/(n_*(n_-1)) -
            2*Kxy.sum()/(m*n_))
metrics['MMD'] = mmd_sub(series_real.values, series_syn.values)

# 6.6 DTW distance average
def dtw(x, y):
    nx, ny = len(x), len(y)
    D = np.full((nx+1, ny+1), np.inf)
    D[0,0] = 0
    for i in range(1, nx+1):
        for j in range(1, ny+1):
            cost = abs(x[i-1] - y[j-1])
            D[i,j] = cost + min(D[i-1,j], D[i,j-1], D[i-1,j-1])
    return D[nx, ny]
segs, L = 5, min(nt, 1000)
dvals = []
for _ in range(segs):
    s = np.random.randint(0, nt-L)
    dvals.append(dtw(y[s:s+L], synthetic[s:s+L]))
metrics['DTW avg'] = np.mean(dvals)

# 6.7 Classification distinguishability
w = 50
X, yl = [], []
for i in range(nt-w):
    X.append(y[i:i+w]);    yl.append(0)
    X.append(synthetic[i:i+w]); yl.append(1)
X = np.array(X).reshape(-1, w)
yl = np.array(yl)
Xtr, Xte, ytr, yte = train_test_split(X, yl, test_size=0.3, random_state=42)
clf = RandomForestClassifier(n_estimators=100, random_state=42).fit(Xtr, ytr)
metrics['Clf Acc'] = accuracy_score(yte, clf.predict(Xte))

# %% 7. Metrics Summary & Visualization
# -------------------------------------
results = pd.Series(metrics).to_frame('Value')
print(results)
results.plot(kind='bar', figsize=(10, 4), legend=False)
plt.title('SDG vs Real Metrics'); plt.tight_layout(); plt.show()
